{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_stats(url, num_its):\n",
    "    '''\n",
    "    Parameters:\n",
    "    url (str): Reddit url where we'll scrape data from \n",
    "    example: 'http://www.reddit.com/r/cryptocurrency/top.json?sort=top&t=year'\n",
    "    \n",
    "    num_its (int): The number of times specified to run the program using the 'after' endpoint\n",
    "    \n",
    "    Returns:\n",
    "    dfs (DataFrame): DataFrame containing post title's, date/time posted, and the number of upvotes\n",
    "    \n",
    "    '''\n",
    "    # delay program a bit to avoid getting blocked by Reddit\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # create lists to hold the post title (text), time in utc format, and the number of upvotes\n",
    "    author = []\n",
    "    title = []\n",
    "    selftext = []\n",
    "    created_utc = []\n",
    "    ups = []\n",
    "    downs = []\n",
    "    upvote_ratio = []\n",
    "    num_comments = []\n",
    "    total_awards = []\n",
    "    \n",
    "\n",
    "    # I decided to use the requests package to scrape the data (which is in JSON format)\n",
    "    r = requests.get(url,  headers={'user-agent': 'Mozilla/5.0'})\n",
    "\n",
    "    # the title, time, and upvotes can be found in \"children\", which can be found in \"data\"\n",
    "    for post in r.json()['data']['children']:\n",
    "        author.append(post['data']['author'])\n",
    "        title.append(post['data']['title'])\n",
    "        selftext.append(post['data']['selftext'])\n",
    "        created_utc.append(post['data']['created_utc'])\n",
    "        ups.append(post['data']['ups'])\n",
    "        downs.append(post['data']['downs'])\n",
    "        upvote_ratio.append(post['data']['upvote_ratio'])\n",
    "        num_comments.append(post['data']['num_comments'])\n",
    "        total_awards.append(post['data']['total_awards_received'])\n",
    "        \n",
    "    num = 0\n",
    "    \n",
    "    # there is an \"after\" attribute in the url which essentially loops to the next page with more posts\n",
    "    # I put a try/except to break out of the function once the data is null\n",
    "    while num < num_its:\n",
    "        try:\n",
    "            urla = url + '&after=' + r.json()['data']['after']\n",
    "            r = requests.get(urla, headers={'user-agent': 'Mozilla/5.0'})\n",
    "            for post in r.json()['data']['children']:\n",
    "                author.append(post['data']['author'])\n",
    "                title.append(post['data']['title'])\n",
    "                selftext.append(post['data']['selftext'])\n",
    "                created_utc.append(post['data']['created_utc'])\n",
    "                ups.append(post['data']['ups'])\n",
    "                downs.append(post['data']['downs'])\n",
    "                upvote_ratio.append(post['data']['upvote_ratio'])\n",
    "                num_comments.append(post['data']['num_comments'])\n",
    "                total_awards.append(post['data']['total_awards_received'])\n",
    "\n",
    "\n",
    "            num += 1\n",
    "        except:\n",
    "            num = num_its\n",
    "            break\n",
    "        \n",
    "    author = np.array(author)\n",
    "    title = np.array(title)\n",
    "    selftext = np.array(selftext)\n",
    "    created_utc = np.array(created_utc)\n",
    "    ups = np.array(ups)\n",
    "    downs = np.array(downs)\n",
    "    upvote_ratio = np.array(upvote_ratio)\n",
    "    num_comments = np.array(num_comments)\n",
    "    total_awards = np.array(total_awards)\n",
    "    \n",
    "    dfs = pd.DataFrame({'Author': author,\n",
    "                        'Title': title,\n",
    "                        'Selftext': selftext,\n",
    "                        'Created Utc': created_utc,\n",
    "                        'Ups': ups,\n",
    "                        'Downs': downs,\n",
    "                        'Upvote Ratio': upvote_ratio,\n",
    "                        'Num Comments': num_comments,\n",
    "                        'Total Awards': total_awards,\n",
    "                        })\n",
    "\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "massive-death",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scrape\n",
    "url = 'http://www.reddit.com/r/bitcoin/top.json?sort=top&t=year'\n",
    "df_rd = get_reddit_stats(url,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contained-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd['Date'] = pd.to_datetime(df_rd['Created Utc'] , unit = 's').dt.date\n",
    "df_rd = df_rd.sort_values('Date', ascending=False)\n",
    "\n",
    "# Drop posts with the same post titles\n",
    "df_rd.drop_duplicates(subset = 'Title',keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "difficult-stationery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fewer-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd.drop(columns=['Downs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solid-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd.to_csv('df_rd_row.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-benefit",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_rd.hist(column='Num Comments', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-minnesota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-lawrence",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-nutrition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for post in r.json()['data']['children']:\n",
    "    print()\n",
    "    print()\n",
    "    counter += 1\n",
    "    print('=================')\n",
    "    for p in post['data'].items():\n",
    "        print(p)\n",
    "    if counter >2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
